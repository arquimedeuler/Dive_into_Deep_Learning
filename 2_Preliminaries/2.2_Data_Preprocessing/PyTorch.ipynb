{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78484c08-8804-4845-aec7-4cd6c4d8185f",
   "metadata": {},
   "source": [
    "# 2.2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f6417-2853-4cd8-8a82-1147f203e498",
   "metadata": {},
   "source": [
    "So far, we have been working with synthetic data that arrived in ready-made tensors. However, to apply deep learning in the wild we must extract messy data stored in arbitrary formats, and preprocess it to suit our needs. Fortunately, the pandas library can do much of the heavy lifting. This section, while no substitute for a proper [pandas tutorial](https://pandas.pydata.org/docs/user_guide/10min.html), will give you a crash course on some of the most common routines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a27fe-1b0f-4812-aa88-d5717dc4c812",
   "metadata": {},
   "source": [
    "## 2.2.1. Reading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f466def-a348-4052-a8da-c56a047266f3",
   "metadata": {},
   "source": [
    "Comma-separated values (CSV) files are ubiquitous for the storing of tabular (spreadsheet-like) data. In them, each line corresponds to one record and consists of several (comma-separated) fields, e.g., “Albert Einstein,March 14 1879,Ulm,Federal polytechnic school,field of gravitational physics”. To demonstrate how to load CSV files with `pandas`, we create a CSV file below `../data/house_tiny.csv`. This file represents a dataset of homes, where each row corresponds to a distinct home and the columns correspond to the number of rooms (`NumRooms`), the roof type (`RoofType`), and the price (`Price`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af085ff4-ca34-4f4e-9209-3a9e034a03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join(\"..\", \"data\"), exist_ok = True)\n",
    "data_file = os.path.join(\"..\", \"data\", \"house_tiny.csv\")\n",
    "with open(data_file, \"w\") as f:\n",
    "    f.write(\"\"\"NumRooms,RoofType,Price\n",
    "NA,NA,127500\n",
    "2,NA,106000\n",
    "4,Slate,178100\n",
    "NA,NA,140000\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f586385c-a347-41d9-96b8-ee5eda0fb7ba",
   "metadata": {},
   "source": [
    "Now let’s import pandas and load the dataset with `read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7ce687-0fd7-47af-8ea7-db515be35ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms RoofType   Price\n",
      "0       NaN      NaN  127500\n",
      "1       2.0      NaN  106000\n",
      "2       4.0    Slate  178100\n",
      "3       NaN      NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018ece7-05c1-4a04-a932-591b9e8ffbe7",
   "metadata": {},
   "source": [
    "## 2.2.2. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9139e988-5586-41f6-9c59-0e28039c131b",
   "metadata": {},
   "source": [
    "In supervised learning, we train models to predict a designated target value, given some set of input values. Our first step in processing the dataset is to separate out columns corresponding to input versus target values. We can select columns either by name or via integer-location based indexing (iloc).\n",
    "\n",
    "You might have noticed that pandas replaced all CSV entries with value NA with a special `NaN` (_not a number_) value. This can also happen whenever an entry is empty, e.g., “3,,,270000”. These are called _missing values_ and they are the “bed bugs” of data science, a persistent menace that you will confront throughout your career. Depending upon the context, missing values might be handled either via _imputation_ or _deletion_. Imputation replaces missing values with estimates of their values while deletion simply discards either those rows or those columns that contain missing values.\n",
    "\n",
    "Here are some common imputation heuristics. For categorical input fields, we can treat `NaN` as a category. Since the `RoofType` column takes values `Slate` and `NaN`, pandas can convert this column into two columns `RoofType_Slate` and `RoofType_nan`. A row whose roof type is `Slate` will set values of `RoofType_Slate` and `RoofType_nan` to 1 and 0, respectively. The converse holds for a row with a missing `RoofType` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc64ac3c-1643-483c-817e-d5945efe2785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       NaN           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       NaN           False          True\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs = pd.get_dummies(inputs, dummy_na = True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdda5071-c109-4386-8b1d-fc2761e74805",
   "metadata": {},
   "source": [
    "For missing numerical values, one common heuristic is to replace the `NaN` entries with the mean value of the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6744ce-a033-48bc-afd2-eb4baf08b4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  RoofType_Slate  RoofType_nan\n",
      "0       3.0           False          True\n",
      "1       2.0           False          True\n",
      "2       4.0            True         False\n",
      "3       3.0           False          True\n"
     ]
    }
   ],
   "source": [
    "inputs = inputs.fillna(inputs.mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2216a2e-6206-4e64-8e05-2ae125552499",
   "metadata": {},
   "source": [
    "## 2.2.3. Conversion to the Tensor Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3292759a-4d47-49b1-ae18-d9d8a735a5f2",
   "metadata": {},
   "source": [
    "Now that all the entries in `inputs` and `targets` are numerical, we can load them into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cea06c7-6d73-443a-9b67-56fde2b7ab7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 0., 1.],\n",
       "         [2., 0., 1.],\n",
       "         [4., 1., 0.],\n",
       "         [3., 0., 1.]], dtype=torch.float64),\n",
       " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor(inputs.to_numpy(dtype = float))\n",
    "y = torch.tensor(targets.to_numpy(dtype = float))\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5018d-0012-45c6-ab07-2e843fea1633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
